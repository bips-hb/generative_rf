---
title: "Compare Generative RF with Normalizing Flows on Moons data"
output: html_document
---
  
  
```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(ggplot2)
library(ranger)
library(reticulate)
library(fdm2id)
source("generative_ranger.R")
```

```{python, echo=FALSE, warning=FALSE, message=FALSE}
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import datasets
import torch
import pyro
import pyro.distributions as dist
import pyro.distributions.transforms as T
import matplotlib.pyplot as plt
```
# Parameters
```{r}
n <- 200L # of each class
n_new <- 300L
```

# Use moons data
```{r}
x_train_df <- data.twomoons(n = n)[, 1:2]
x_train <- as.matrix(x_train_df)
x_test_df <- data.twomoons(n = n)[, 1:2]
x_test <- as.matrix(x_test_df)
```

# Create synthetic data with Pyro NF (Python)
```{python}
# Create base distribution for flow
base_dist = dist.Normal(torch.zeros(2), torch.ones(2))

# Define coupling spline transformation (see https://docs.pyro.ai/en/stable/distributions.html?highlight=Spline#splinecoupling)
spline_transform = T.spline_coupling(2, count_bins=16)
flow_dist = dist.TransformedDistribution(base_dist, [spline_transform])

# Train Flow
steps = 1001
dataset = torch.tensor(r.x_train, dtype=torch.float)
optimizer = torch.optim.Adam(spline_transform.parameters(), lr=1e-2)
for step in range(steps+1):
  optimizer.zero_grad()
  loss = -flow_dist.log_prob(dataset).mean()
  loss.backward()
  optimizer.step()
  flow_dist.clear_cache()
  
  if step % 200 == 0:
    print('step: {}, loss: {}'.format(step, loss.item()))

# Generate new samples
X_new = flow_dist.sample(torch.Size([r.n_new,])).detach().numpy()
```

# Generative RF
```{r}
library(ranger)
source("generative_ranger.R")
x_new_rf <- generative_ranger(x_real = x_train_df, n_new = n_new, num.trees = 100, 
                              min.node.size = 30)
```

# Plot
```{r}
x_new_nf <- py$X_new
colnames(x_new_nf) <- colnames(x_train)
df <- rbind(data.frame(data = "Original", x_train_df), 
            data.frame(data = "NF", as.data.frame(x_new_nf)), 
            data.frame(data = "RF", as.data.frame(x_new_rf)))
df$data <- factor(df$data)
ggplot(df, aes(x = X, y = Y, color = data)) + 
  geom_point()
```

# Compare
## Correlations (as in Goncalves et al. 2020)
Data utility metric, i.e. how close is the data to the original?
```{r}
util <- function(orig, synth) {
  norm(cor(orig) - cor(synth), type = "F")
}
c(NF = util(x_train, x_new_nf), 
  RF = util(x_train, x_new_rf))
```

## Proportion of overfitting (as in Lenz et al. 2021)
Data disclosure metric, i.e. is it too close to the original?
```{r}
disc <- function(orig_train, orig_test, synth) {
  (util(orig_test, synth) - util(orig_train, synth)) / util(orig_test, synth)
}
c(NF = disc(x_train, x_test, x_new_nf),
  RF = disc(x_train, x_test, x_new_rf))
```





